{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11249653,"sourceType":"datasetVersion","datasetId":7029569}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n# reading the two files \nexplicit= pd.read_excel('../input/sexually-explicit/harashment.xlsx')\nnon_explicit=pd.read_excel('../input/sexually-explicit/Normal comments.xlsx')\n#taking the two frames as one dataframe data(appending)\ndata = pd.concat([explicit, non_explicit], ignore_index=True)\n#data=data[['comments','label']]\ndata=data.sample(frac=1).reset_index(drop=True)\nprint(data.tail())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:13.615703Z","iopub.execute_input":"2025-09-01T14:33:13.615904Z","iopub.status.idle":"2025-09-01T14:33:17.280113Z","shell.execute_reply.started":"2025-09-01T14:33:13.615888Z","shell.execute_reply":"2025-09-01T14:33:17.279383Z"}},"outputs":[{"name":"stdout","text":"                                                comments  label\n34707  በመጀመርያ እግዚአብሔር ይመስገን ኢትዮጵያ ሀገሬ እንዲህ የአለም መነጋገር...      0\n34708  አንድ የተወሰነ መሪ የሰማኋትን አንዲት ሴት ስልክ ቁጥር እየጠየቀች ነበር...      1\n34709  ያሳዝናል የትግሬ እናቶች በስንቱ ያልቅሱ በዘመናት ልጅ እያጡ ያነቡ እናቶ...      0\n34710  ይህ ክስተት የተከሰተው ምሽት ላይ ነው.ከትምህርቴ እየመጣሁ ነበር እና አ...      1\n34711  ኢሳያስ ግን በየፕሮጀክቱ ከሚያንከራትቱት የፓርላማ ውይይት ቢያሳዩት ይሻል...      0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# pre-processing of the dataset\n#normalizarion\nimport re\n#method to normalize character level missmatch such as ጸሀይ and ፀሐይ\ndef normalization(input_token):\n    rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',input_token)\n    rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n    rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n    rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n    rep5=re.sub('[ሕኅ]','ህ',rep4)\n    rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n    rep7=re.sub('[ሠ]','ሰ',rep6)\n    rep8=re.sub('[ሡ]','ሱ',rep7)\n    rep9=re.sub('[ሢ]','ሲ',rep8)\n    rep10=re.sub('[ሣ]','ሳ',rep9)\n    rep11=re.sub('[ሤ]','ሴ',rep10)\n    rep12=re.sub('[ሥ]','ስ',rep11)\n    rep13=re.sub('[ሦ]','ሶ',rep12)\n    rep14=re.sub('[ዓኣዐ]','አ',rep13)\n    rep15=re.sub('[ዑ]','ኡ',rep14)\n    rep16=re.sub('[ዒ]','ኢ',rep15)\n    rep17=re.sub('[ዔ]','ኤ',rep16)\n    rep18=re.sub('[ዕ]','እ',rep17)\n    rep19=re.sub('[ዖ]','ኦ',rep18)\n    rep20=re.sub('[ጸ]','ፀ',rep19)\n    rep21=re.sub('[ጹ]','ፁ',rep20)\n    rep22=re.sub('[ጺ]','ፂ',rep21)\n    rep23=re.sub('[ጻ]','ፃ',rep22)\n    rep24=re.sub('[ጼ]','ፄ',rep23)\n    rep25=re.sub('[ጽ]','ፅ',rep24)\n    rep26=re.sub('[ጾ]','ፆ',rep25)\n    rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n    rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n    rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n    rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n    rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n    rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n    rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n    rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n    rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n    rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n    rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n    rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n    rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n    rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n    rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n    rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n    rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n    rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n    rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n    rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n    rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n    rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ\n    return rep48","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:17.281426Z","iopub.execute_input":"2025-09-01T14:33:17.281793Z","iopub.status.idle":"2025-09-01T14:33:17.293334Z","shell.execute_reply.started":"2025-09-01T14:33:17.281774Z","shell.execute_reply":"2025-09-01T14:33:17.292597Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#normalization of Amharic characters having the same sound and meaning\ndata['comments'] = data['comments'].astype(str)\ndata['comments']=data['comments'].apply(lambda x: normalization(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:17.294068Z","iopub.execute_input":"2025-09-01T14:33:17.294316Z","iopub.status.idle":"2025-09-01T14:33:18.424243Z","shell.execute_reply.started":"2025-09-01T14:33:17.294291Z","shell.execute_reply":"2025-09-01T14:33:18.423648Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#pre-processing function\ndef remove_non_amharic(text):\n  # Define a regex pattern for Amharic characters (Unicode range)\n    amharic_pattern = r'[^\\u1200-\\u137F\\s]'  # Unicode range for Amharic characters\n    amharic_pattern=r'[\\u1200-\\u137F]*[0-9]+[\\u1200-\\u137F]*'#removing digits\n    amharic_pattern = r'[፡-፨]'  # Unicode range for Amharic punctuation marks\n    amharic_pattern=r'[^\\w\\s]'# removing white spaces\n    # Use re.sub to replace non-Amharic characters with an empty string\n    cleaned_text = re.sub(amharic_pattern, '', text)\n    return cleaned_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:18.426047Z","iopub.execute_input":"2025-09-01T14:33:18.426264Z","iopub.status.idle":"2025-09-01T14:33:18.430378Z","shell.execute_reply.started":"2025-09-01T14:33:18.426247Z","shell.execute_reply":"2025-09-01T14:33:18.429675Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#spliting the dataset into training and testing set\ntrain_val_df, test_dataset = train_test_split(data, test_size=0.20, random_state=42)\ntrain_dataset, evaluation_dataset = train_test_split(train_val_df, test_size=0.10, random_state=42)\nprint('Training dataset shape: ', train_dataset.shape)\nprint('Validation dataset shape: ', evaluation_dataset.shape)\nprint('Testing dataset shape: ', test_dataset.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:18.431059Z","iopub.execute_input":"2025-09-01T14:33:18.431321Z","iopub.status.idle":"2025-09-01T14:33:18.884378Z","shell.execute_reply.started":"2025-09-01T14:33:18.431297Z","shell.execute_reply":"2025-09-01T14:33:18.883455Z"}},"outputs":[{"name":"stdout","text":"Training dataset shape:  (24992, 2)\nValidation dataset shape:  (2777, 2)\nTesting dataset shape:  (6943, 2)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"msk = np.random.rand(len(data)) < 0.8\ntrain_dataset = data[msk]\ntest_dataset = data[~msk]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:18.885669Z","iopub.execute_input":"2025-09-01T14:33:18.886027Z","iopub.status.idle":"2025-09-01T14:33:18.892900Z","shell.execute_reply.started":"2025-09-01T14:33:18.886007Z","shell.execute_reply":"2025-09-01T14:33:18.892167Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"    pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:18.893677Z","iopub.execute_input":"2025-09-01T14:33:18.893910Z","iopub.status.idle":"2025-09-01T14:33:22.176034Z","shell.execute_reply.started":"2025-09-01T14:33:18.893894Z","shell.execute_reply":"2025-09-01T14:33:22.175114Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from datasets import Dataset\n#convert format of the dataset to HuggingFace Dataset from Pandas DataFrame\ntrain_dataset=Dataset.from_pandas(train_dataset)\ntest_dataset=Dataset.from_pandas(test_dataset)\nevaluation_dataset=Dataset.from_pandas(evaluation_dataset)\nprint(test_dataset)\nprint(train_dataset)\nprint(evaluation_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:22.177108Z","iopub.execute_input":"2025-09-01T14:33:22.177347Z","iopub.status.idle":"2025-09-01T14:33:22.853145Z","shell.execute_reply.started":"2025-09-01T14:33:22.177322Z","shell.execute_reply":"2025-09-01T14:33:22.852366Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['comments', 'label', '__index_level_0__'],\n    num_rows: 6941\n})\nDataset({\n    features: ['comments', 'label', '__index_level_0__'],\n    num_rows: 27771\n})\nDataset({\n    features: ['comments', 'label', '__index_level_0__'],\n    num_rows: 2777\n})\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#combine the train and test dataset into one datset\nimport datasets\nmain_dataset= datasets.DatasetDict({\n    'train': train_dataset,\n    'test': test_dataset,\n    'evaluate': evaluation_dataset\n})\n# training and testing data size\ntraining_data_size = main_dataset['train'].num_rows\ntesting_data_size = main_dataset['test'].num_rows\nevaluation_data_size = main_dataset['evaluate'].num_rows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:22.854044Z","iopub.execute_input":"2025-09-01T14:33:22.854516Z","iopub.status.idle":"2025-09-01T14:33:22.858852Z","shell.execute_reply.started":"2025-09-01T14:33:22.854485Z","shell.execute_reply":"2025-09-01T14:33:22.858229Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nsnapshot_download(repo_id=\"bert-base-uncased\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:22.861313Z","iopub.execute_input":"2025-09-01T14:33:22.861931Z","iopub.status.idle":"2025-09-01T14:33:23.316411Z","shell.execute_reply.started":"2025-09-01T14:33:22.861908Z","shell.execute_reply":"2025-09-01T14:33:23.315597Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94661c89bd6d4e3b9f88058c9b0262c5"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'/root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\n# This will load the model and its tokenizer from the downloaded files\nmodel = AutoModel.from_pretrained(\"bert-base-uncased\")\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:23.317544Z","iopub.execute_input":"2025-09-01T14:33:23.317807Z","iopub.status.idle":"2025-09-01T14:33:32.941210Z","shell.execute_reply.started":"2025-09-01T14:33:23.317786Z","shell.execute_reply":"2025-09-01T14:33:32.940595Z"}},"outputs":[{"name":"stderr","text":"2025-09-01 14:33:29.999569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756737210.022496   46685 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756737210.029681   46685 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#Have a tokenizer function that uses the tokenizer\ndef tokenize_function(data):\n    return tokenizer(data[\"comments\"], padding=\"max_length\", truncation=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:32.942024Z","iopub.execute_input":"2025-09-01T14:33:32.942604Z","iopub.status.idle":"2025-09-01T14:33:32.946552Z","shell.execute_reply.started":"2025-09-01T14:33:32.942583Z","shell.execute_reply":"2025-09-01T14:33:32.945879Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#Tokenize all the data using the mapping functionality\ntokenized_datasets = main_dataset.map(tokenize_function)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:32.947311Z","iopub.execute_input":"2025-09-01T14:33:32.947515Z","iopub.status.idle":"2025-09-01T14:33:52.976505Z","shell.execute_reply.started":"2025-09-01T14:33:32.947499Z","shell.execute_reply":"2025-09-01T14:33:52.975447Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27771 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c32432253764cfcab1bd98f7de4da78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6941 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f638ae0fb64465a783358513a4cede"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2777 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9396860a8f1b44019080e11f1e27e6f6"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#import torch\nimport torch\n#import Data loader from torch\nfrom torch.utils.data import DataLoader\n#import an optimizer\nfrom torch.optim import AdamW\n#import tqdm for a progress bar\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:52.977678Z","iopub.execute_input":"2025-09-01T14:33:52.977926Z","iopub.status.idle":"2025-09-01T14:33:52.981917Z","shell.execute_reply.started":"2025-09-01T14:33:52.977907Z","shell.execute_reply":"2025-09-01T14:33:52.981177Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#remove the posts column as it is no longer needed\ntokenized_datasets = tokenized_datasets.remove_columns([\"comments\"])\ntokenized_datasets.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:52.982735Z","iopub.execute_input":"2025-09-01T14:33:52.983025Z","iopub.status.idle":"2025-09-01T14:33:52.996324Z","shell.execute_reply.started":"2025-09-01T14:33:52.983000Z","shell.execute_reply":"2025-09-01T14:33:52.995571Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#shuffeling and selecting the needed size of dataset for training and evaluating the model\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(training_data_size))\nsmall_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(testing_data_size))\nsmall_eval_dataset = tokenized_datasets[\"evaluate\"].shuffle(seed=42).select(range(evaluation_data_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:52.997087Z","iopub.execute_input":"2025-09-01T14:33:52.997337Z","iopub.status.idle":"2025-09-01T14:33:53.019833Z","shell.execute_reply.started":"2025-09-01T14:33:52.997316Z","shell.execute_reply":"2025-09-01T14:33:53.019132Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=4)\neval_dataloader = DataLoader(small_eval_dataset, batch_size=4)\ntest_dataloader = DataLoader(small_test_dataset, batch_size=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:53.020561Z","iopub.execute_input":"2025-09-01T14:33:53.020871Z","iopub.status.idle":"2025-09-01T14:33:53.024894Z","shell.execute_reply.started":"2025-09-01T14:33:53.020845Z","shell.execute_reply":"2025-09-01T14:33:53.024195Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#Load auto mode classifier from the pretrained model\nfrom transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:53.025478Z","iopub.execute_input":"2025-09-01T14:33:53.025679Z","iopub.status.idle":"2025-09-01T14:33:53.187572Z","shell.execute_reply.started":"2025-09-01T14:33:53.025657Z","shell.execute_reply":"2025-09-01T14:33:53.186824Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:53.188562Z","iopub.execute_input":"2025-09-01T14:33:53.188843Z","iopub.status.idle":"2025-09-01T14:33:56.406229Z","shell.execute_reply.started":"2025-09-01T14:33:53.188818Z","shell.execute_reply":"2025-09-01T14:33:56.405475Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Instead of importing everything at once\nfrom transformers.training_args import TrainingArguments\nfrom transformers.trainer import Trainer\nfrom transformers import EarlyStoppingCallback\nfrom transformers import EarlyStoppingCallback, IntervalStrategy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:56.407403Z","iopub.execute_input":"2025-09-01T14:33:56.407802Z","iopub.status.idle":"2025-09-01T14:33:57.102767Z","shell.execute_reply.started":"2025-09-01T14:33:56.407763Z","shell.execute_reply":"2025-09-01T14:33:57.101962Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from evaluate import load\ndef custom_metrics(eval_pred):\n    metric1 = load(\"precision\")\n    metric2 = load(\"recall\")\n    metric3 = load(\"f1\")\n    metric4 = load(\"accuracy\")\n\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n\n    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n\n    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:57.103633Z","iopub.execute_input":"2025-09-01T14:33:57.103879Z","iopub.status.idle":"2025-09-01T14:33:57.178697Z","shell.execute_reply.started":"2025-09-01T14:33:57.103852Z","shell.execute_reply":"2025-09-01T14:33:57.178095Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# #load an optimizer\n# optimizer = AdamW(model.parameters(), lr=5e-5)\ntraining_args = TrainingArguments(\n   output_dir=\"./results\",\n   eval_strategy='epoch',\n   save_strategy='epoch',\n   logging_strategy='epoch',\n   num_train_epochs=4,\n   learning_rate=1e-5,\n   per_device_train_batch_size=4,  # batch size per device during training\n   per_device_eval_batch_size=4,   # batch size for evaluation\n   warmup_steps=1000,                # number of warmup steps for learning rate\n   weight_decay=0.01,\n   run_name=\"sexually explicit comments\",# strength of weight decay\n   logging_dir='./logs',            # directory for storing logs\n   logging_steps=20,\n   report_to=\"none\",\n   load_best_model_at_end= True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:57.179343Z","iopub.execute_input":"2025-09-01T14:33:57.179538Z","iopub.status.idle":"2025-09-01T14:33:57.213270Z","shell.execute_reply.started":"2025-09-01T14:33:57.179522Z","shell.execute_reply":"2025-09-01T14:33:57.212761Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=custom_metrics,\n    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:57.214037Z","iopub.execute_input":"2025-09-01T14:33:57.214478Z","iopub.status.idle":"2025-09-01T14:33:57.513603Z","shell.execute_reply.started":"2025-09-01T14:33:57.214452Z","shell.execute_reply":"2025-09-01T14:33:57.512857Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"train_result=trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T14:33:57.514735Z","iopub.execute_input":"2025-09-01T14:33:57.515002Z","iopub.status.idle":"2025-09-01T16:35:06.732490Z","shell.execute_reply.started":"2025-09-01T14:33:57.514975Z","shell.execute_reply":"2025-09-01T16:35:06.731750Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13888' max='13888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13888/13888 2:01:07, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.635800</td>\n      <td>0.609752</td>\n      <td>0.636988</td>\n      <td>0.624055</td>\n      <td>0.616976</td>\n      <td>0.624055</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.600100</td>\n      <td>0.596886</td>\n      <td>0.651852</td>\n      <td>0.647461</td>\n      <td>0.645800</td>\n      <td>0.647461</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.588200</td>\n      <td>0.588110</td>\n      <td>0.658461</td>\n      <td>0.647101</td>\n      <td>0.642123</td>\n      <td>0.647101</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.580700</td>\n      <td>0.588853</td>\n      <td>0.654082</td>\n      <td>0.648181</td>\n      <td>0.645828</td>\n      <td>0.648181</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n# Now you can make predictions\npredictions = trainer.predict(small_test_dataset)\n# Get the predicted labels and true labels\npredicted_labels = np.argmax(predictions.predictions, axis=1)\ntrue_labels =  small_test_dataset['label']\n# Calculate the confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\nprint(cm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T16:37:30.822105Z","iopub.execute_input":"2025-09-01T16:37:30.822369Z","iopub.status.idle":"2025-09-01T16:39:54.454155Z","shell.execute_reply.started":"2025-09-01T16:37:30.822345Z","shell.execute_reply":"2025-09-01T16:39:54.453583Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"[[1810 1671]\n [ 744 2716]]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(true_labels, predicted_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T16:40:11.026536Z","iopub.execute_input":"2025-09-01T16:40:11.026849Z","iopub.status.idle":"2025-09-01T16:40:11.040422Z","shell.execute_reply.started":"2025-09-01T16:40:11.026827Z","shell.execute_reply":"2025-09-01T16:40:11.039774Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.71      0.52      0.60      3481\n           1       0.62      0.78      0.69      3460\n\n    accuracy                           0.65      6941\n   macro avg       0.66      0.65      0.65      6941\nweighted avg       0.66      0.65      0.65      6941\n\n","output_type":"stream"}],"execution_count":28}]}